{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Conv2DTranspose\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "import os\n",
    "import shutil\n",
    "from tensorflow.keras import metrics\n",
    "from keras.preprocessing import image_dataset_from_directory\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.xception import preprocess_input\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD, RMSprop\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start with just one image\n",
    "1. upload image\n",
    "2. create duplicate image with lines\n",
    "3. build model and try to run with one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Data/Unruled/sc0181_NEW.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-7b8d89f6889f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#read in one image as target (or y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data/Unruled/sc0181_NEW.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#show image from array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2808\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2809\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2810\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data/Unruled/sc0181_NEW.jpg'"
     ]
    }
   ],
   "source": [
    "#read in one image as target (or y)\n",
    "y = np.array(Image.open('Data/Unruled/sc0181_NEW.jpg'))\n",
    "#show image from array\n",
    "Image.fromarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-3d861059fa55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-117af9a8e7d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#2. create lines on target image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#[row_start:row_stop: row_step, col_start:col_stop:col_step ]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m130\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "#2. create lines on target image\n",
    "\n",
    "X = np.array(y)\n",
    "#[row_start:row_stop: row_step, col_start:col_stop:col_step ] \n",
    "X[::40+np.random.randint(-2,2),:] = 80+np.random.randint(-60, 130)\n",
    "#show new image from array\n",
    "Image.fromarray(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_to_predict = np.array(Image.open('Data/Original_Ruled/IMG_0002.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-8a3a5664614d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1,2, figsize = (10,10))\n",
    "[ax.imshow(x) for ax, x in zip(axs.flatten(), [X, y])];\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-3c1245ba135a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#reshape to fit into model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "#reshape to fit into model\n",
    "X = X.reshape(*X.shape,1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bring in entire data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y\n",
    "y_list = []\n",
    "for image in os.listdir('Data/y_variables/Unruled'):\n",
    "    \n",
    "    y_image = np.array((Image.open(f'Data/y_variables/Unruled/{image}')))\n",
    "    y_image = y_image.reshape(*y_image.shape,1)\n",
    "    y_list.append(y_image)\n",
    "                  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X\n",
    "\n",
    "X_list = []\n",
    "for image in os.listdir('Data/X_variables/computer_generated_lines'):\n",
    "    \n",
    "    \n",
    "    X_image = np.array(Image.open(f'Data/X_variables/computer_generated_lines/{image}'))\n",
    "    \n",
    "    #X_image = np.array((Image.open(f'Data/computer_generated_lines/{image}'))).reshape(*X_image.shape,1)\n",
    "    #print(type(x_image))\n",
    "    X_image = X_image.reshape(*X_image.shape,1)\n",
    "    X_list.append(X_image)\n",
    "                  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(669, 669)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_list), len(X_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 669 images belonging to 1 classes.\n",
      "Found 669 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# train_datagen = ImageDataGenerator()\n",
    "# #validation_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "# X_train_generator = train_datagen.flow_from_directory(\n",
    "#         '/Users/megan/Galvanize/capstone_folder/Capstone_3/Data/X_variables',\n",
    "#         target_size=(500, 400),\n",
    "#         color_mode='grayscale',\n",
    "#         batch_size=32,\n",
    "#         class_mode='input')\n",
    "# y_train_generator = train_datagen.flow_from_directory(\n",
    "#         '/Users/megan/Galvanize/capstone_folder/Capstone_3/Data/y_variables',\n",
    "#         target_size=(500, 400),\n",
    "#         color_mode='grayscale',\n",
    "#         batch_size=32,\n",
    "#         class_mode='input')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[102.],\n",
       "         [102.],\n",
       "         [102.],\n",
       "         ...,\n",
       "         [102.],\n",
       "         [102.],\n",
       "         [102.]],\n",
       "\n",
       "        [[243.],\n",
       "         [243.],\n",
       "         [243.],\n",
       "         ...,\n",
       "         [243.],\n",
       "         [243.],\n",
       "         [243.]],\n",
       "\n",
       "        [[246.],\n",
       "         [246.],\n",
       "         [246.],\n",
       "         ...,\n",
       "         [246.],\n",
       "         [246.],\n",
       "         [246.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[245.],\n",
       "         [245.],\n",
       "         [245.],\n",
       "         ...,\n",
       "         [245.],\n",
       "         [245.],\n",
       "         [245.]],\n",
       "\n",
       "        [[245.],\n",
       "         [245.],\n",
       "         [245.],\n",
       "         ...,\n",
       "         [245.],\n",
       "         [245.],\n",
       "         [245.]],\n",
       "\n",
       "        [[245.],\n",
       "         [245.],\n",
       "         [245.],\n",
       "         ...,\n",
       "         [245.],\n",
       "         [245.],\n",
       "         [245.]]],\n",
       "\n",
       "\n",
       "       [[[162.],\n",
       "         [162.],\n",
       "         [162.],\n",
       "         ...,\n",
       "         [162.],\n",
       "         [162.],\n",
       "         [162.]],\n",
       "\n",
       "        [[254.],\n",
       "         [254.],\n",
       "         [254.],\n",
       "         ...,\n",
       "         [254.],\n",
       "         [254.],\n",
       "         [254.]],\n",
       "\n",
       "        [[251.],\n",
       "         [251.],\n",
       "         [251.],\n",
       "         ...,\n",
       "         [251.],\n",
       "         [251.],\n",
       "         [251.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[253.],\n",
       "         [253.],\n",
       "         [253.],\n",
       "         ...,\n",
       "         [253.],\n",
       "         [253.],\n",
       "         [253.]],\n",
       "\n",
       "        [[253.],\n",
       "         [253.],\n",
       "         [253.],\n",
       "         ...,\n",
       "         [253.],\n",
       "         [253.],\n",
       "         [253.]],\n",
       "\n",
       "        [[253.],\n",
       "         [253.],\n",
       "         [253.],\n",
       "         ...,\n",
       "         [253.],\n",
       "         [253.],\n",
       "         [253.]]],\n",
       "\n",
       "\n",
       "       [[[ 86.],\n",
       "         [ 80.],\n",
       "         [ 80.],\n",
       "         ...,\n",
       "         [ 83.],\n",
       "         [ 86.],\n",
       "         [ 82.]],\n",
       "\n",
       "        [[240.],\n",
       "         [236.],\n",
       "         [237.],\n",
       "         ...,\n",
       "         [241.],\n",
       "         [243.],\n",
       "         [238.]],\n",
       "\n",
       "        [[240.],\n",
       "         [239.],\n",
       "         [241.],\n",
       "         ...,\n",
       "         [253.],\n",
       "         [254.],\n",
       "         [246.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[242.],\n",
       "         [220.],\n",
       "         [234.],\n",
       "         ...,\n",
       "         [217.],\n",
       "         [246.],\n",
       "         [239.]],\n",
       "\n",
       "        [[237.],\n",
       "         [216.],\n",
       "         [231.],\n",
       "         ...,\n",
       "         [218.],\n",
       "         [248.],\n",
       "         [240.]],\n",
       "\n",
       "        [[233.],\n",
       "         [213.],\n",
       "         [230.],\n",
       "         ...,\n",
       "         [218.],\n",
       "         [249.],\n",
       "         [242.]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[132.],\n",
       "         [132.],\n",
       "         [132.],\n",
       "         ...,\n",
       "         [132.],\n",
       "         [132.],\n",
       "         [132.]],\n",
       "\n",
       "        [[239.],\n",
       "         [239.],\n",
       "         [239.],\n",
       "         ...,\n",
       "         [239.],\n",
       "         [239.],\n",
       "         [239.]],\n",
       "\n",
       "        [[240.],\n",
       "         [240.],\n",
       "         [240.],\n",
       "         ...,\n",
       "         [240.],\n",
       "         [240.],\n",
       "         [240.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[240.],\n",
       "         [240.],\n",
       "         [240.],\n",
       "         ...,\n",
       "         [240.],\n",
       "         [240.],\n",
       "         [240.]],\n",
       "\n",
       "        [[240.],\n",
       "         [240.],\n",
       "         [240.],\n",
       "         ...,\n",
       "         [240.],\n",
       "         [240.],\n",
       "         [240.]],\n",
       "\n",
       "        [[240.],\n",
       "         [240.],\n",
       "         [240.],\n",
       "         ...,\n",
       "         [240.],\n",
       "         [240.],\n",
       "         [240.]]],\n",
       "\n",
       "\n",
       "       [[[ 69.],\n",
       "         [ 69.],\n",
       "         [ 69.],\n",
       "         ...,\n",
       "         [ 69.],\n",
       "         [ 69.],\n",
       "         [ 69.]],\n",
       "\n",
       "        [[248.],\n",
       "         [248.],\n",
       "         [248.],\n",
       "         ...,\n",
       "         [248.],\n",
       "         [248.],\n",
       "         [248.]],\n",
       "\n",
       "        [[251.],\n",
       "         [251.],\n",
       "         [251.],\n",
       "         ...,\n",
       "         [251.],\n",
       "         [251.],\n",
       "         [251.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[249.],\n",
       "         [249.],\n",
       "         [249.],\n",
       "         ...,\n",
       "         [249.],\n",
       "         [249.],\n",
       "         [249.]],\n",
       "\n",
       "        [[249.],\n",
       "         [249.],\n",
       "         [249.],\n",
       "         ...,\n",
       "         [249.],\n",
       "         [249.],\n",
       "         [249.]],\n",
       "\n",
       "        [[249.],\n",
       "         [249.],\n",
       "         [249.],\n",
       "         ...,\n",
       "         [249.],\n",
       "         [249.],\n",
       "         [249.]]],\n",
       "\n",
       "\n",
       "       [[[ 63.],\n",
       "         [ 63.],\n",
       "         [ 63.],\n",
       "         ...,\n",
       "         [ 63.],\n",
       "         [ 63.],\n",
       "         [ 63.]],\n",
       "\n",
       "        [[242.],\n",
       "         [242.],\n",
       "         [242.],\n",
       "         ...,\n",
       "         [242.],\n",
       "         [242.],\n",
       "         [242.]],\n",
       "\n",
       "        [[245.],\n",
       "         [245.],\n",
       "         [245.],\n",
       "         ...,\n",
       "         [245.],\n",
       "         [245.],\n",
       "         [245.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[244.],\n",
       "         [244.],\n",
       "         [244.],\n",
       "         ...,\n",
       "         [244.],\n",
       "         [244.],\n",
       "         [244.]],\n",
       "\n",
       "        [[244.],\n",
       "         [244.],\n",
       "         [244.],\n",
       "         ...,\n",
       "         [244.],\n",
       "         [244.],\n",
       "         [244.]],\n",
       "\n",
       "        [[244.],\n",
       "         [244.],\n",
       "         [244.],\n",
       "         ...,\n",
       "         [244.],\n",
       "         [244.],\n",
       "         [244.]]]], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(X_train_generator)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # of images(669), X images, y images, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`x` (images tensor) and `y` (labels) should have the same length. Found: x.shape = (500, 400, 1), y.shape = (669, 500, 400, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-58c54b122b1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     shuffle=False)\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mflow\u001b[0;34m(self, x, y, batch_size, shuffle, sample_weight, seed, save_to_dir, save_prefix, save_format, subset)\u001b[0m\n\u001b[1;32m    864\u001b[0m         \u001b[0msave_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_prefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m         subset=subset)\n\u001b[0m\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   def flow_from_directory(self,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, image_data_generator, batch_size, shuffle, sample_weight, seed, data_format, save_to_dir, save_prefix, save_format, subset, dtype)\u001b[0m\n\u001b[1;32m    459\u001b[0m         \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras_preprocessing/image/numpy_array_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, image_data_generator, batch_size, shuffle, sample_weight, seed, data_format, save_to_dir, save_prefix, save_format, subset, dtype)\u001b[0m\n\u001b[1;32m     87\u001b[0m                              \u001b[0;34m'should have the same length. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                              \u001b[0;34m'Found: x.shape = %s, y.shape = %s'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                              (np.asarray(x).shape, np.asarray(y).shape))\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             raise ValueError('`x` (images tensor) and `sample_weight` '\n",
      "\u001b[0;31mValueError\u001b[0m: `x` (images tensor) and `y` (labels) should have the same length. Found: x.shape = (500, 400, 1), y.shape = (669, 500, 400, 1)"
     ]
    }
   ],
   "source": [
    "# image_generator = train_datagen.flow(\n",
    "#     x=X_list,\n",
    "#     y=y_list,\n",
    "#     batch_size=32,\n",
    "#     shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 498, 398, 32)      320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 496, 396, 32)      9248      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 494, 394, 32)      9248      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 494, 394, 128)     4224      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 494, 394, 64)      8256      \n",
      "_________________________________________________________________\n",
      "bottleneck (Dense)           (None, 494, 394, 2)       130       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 494, 394, 64)      192       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 494, 394, 128)     8320      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 494, 394, 784)     101136    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 496, 396, 32)      225824    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 498, 398, 32)      9248      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 500, 400, 32)      9248      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 500, 400, 1)       289       \n",
      "=================================================================\n",
      "Total params: 385,683\n",
      "Trainable params: 385,683\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#3.build the model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input((500, 400,1)))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (3,3), activation = 'relu'))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (3,3), activation = 'relu'))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (3,3), activation = 'relu'))\n",
    "\n",
    "model.add(Dense(128,  activation='relu'))\n",
    "model.add(Dense(64,  activation='relu'))\n",
    "model.add(Dense(2,    activation='linear', name=\"bottleneck\"))\n",
    "model.add(Dense(64,  activation='relu'))\n",
    "model.add(Dense(128,  activation='relu'))\n",
    "model.add(Dense(784,  activation='linear'))\n",
    "\n",
    "model.add(Conv2DTranspose(filters = 32, kernel_size=(3,3), activation='relu'))\n",
    "model.add(Conv2DTranspose(filters = 32, kernel_size=(3,3), activation='relu'))\n",
    "model.add(Conv2DTranspose(filters = 32, kernel_size=(3,3), activation='relu'))\n",
    "model.add(Conv2DTranspose(filters = 1, kernel_size=(3,3), activation='linear', padding='same'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 compile your model\n",
    "\n",
    "# METRICS = [ metrics.CategoricalAccuracy(name='ACCURACY'),\n",
    "#             metrics.AUC(name='AUC',curve='pr', multi_label=False),\n",
    "#            metrics.SensitivityAtSpecificity(0.5, name='Sens@Spec'),\n",
    "#            metrics.SpecificityAtSensitivity(0.5, name='Spec@Sens')]\n",
    "\n",
    "# METRICS = [ metrics.Accuracy(name='ACCURACY'),\n",
    "#             metrics.AUC(name='AUC')]\n",
    "\n",
    "model.compile(loss = 'mse', optimizer = 'adam', metrics='Accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 set up tensorboard\n",
    "\n",
    "checkpoint_filepath = './tmp/checkpoint'\n",
    "tensorboard = TensorBoard(log_dir=\"./logs\",\n",
    "    histogram_freq=2,\n",
    "    write_graph=True,\n",
    "    write_images=True,\n",
    "    update_freq=\"epoch\",\n",
    "    profile_batch=2,\n",
    "    embeddings_freq=0,\n",
    "    embeddings_metadata=None)\n",
    "\n",
    "# early_stopping = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
    "# model_cp = ModelCheckpoint(filepath=checkpoint_filepath, save_best_only=True)\n",
    "model_cp = ModelCheckpoint(filepath=checkpoint_filepath)\n",
    "early_stopping = EarlyStopping(monitor='loss',patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#created generator that zips together X and y\n",
    "\n",
    "def new_autoencoder_generator(X_train_generator, y_train_generator):\n",
    "    for \n",
    "    \n",
    "    return new_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`y` argument is not supported when using `keras.utils.Sequence` as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-eaa8ecc24a5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#         model.fit(x=np.array([X]), y=np.array([y]), epochs = 500, verbose=1, callbacks=[tensorboard, early_stopping,  model_cp])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensorboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mmodel_cp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1061\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, shuffle, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[1;32m    897\u001b[0m                **kwargs):\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_none_or_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m       raise ValueError(\"`y` argument is not supported when using \"\n\u001b[0m\u001b[1;32m    900\u001b[0m                        \"`keras.utils.Sequence` as input.\")\n\u001b[1;32m    901\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_none_or_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: `y` argument is not supported when using `keras.utils.Sequence` as input."
     ]
    }
   ],
   "source": [
    "# for X in X_list:\n",
    "#     for y in y_list:\n",
    "\n",
    "#         model.fit(x=np.array([X]), y=np.array([y]), epochs = 500, verbose=1, callbacks=[tensorboard, early_stopping,  model_cp])\n",
    "\n",
    "model.fit(x=np.array(X_list), y=, epochs = 100, verbose=1, callbacks=[tensorboard, early_stopping,  model_cp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 500, 400, 1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(X_train_generator).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.keras.preprocessing.image.DirectoryIterator"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!tensorboard --logdir=logs\n",
    "np.array(X_list).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = model.predict(np.array([X]))\n",
    "result = model.predict(np.array([image_to_predict.reshape(*image_to_predict.shape, 1)]))\n",
    "result = result.astype(np.uint8).reshape(500,400)\n",
    "Image.fromarray(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to create all images with random line widths and depth - only need to do once\n",
    "\n",
    "# for image in os.listdir('Data/Unruled'):\n",
    "\n",
    "#     y=np.array((Image.open(f'Data/Unruled/{image}')))\n",
    "#     X = np.array(y)\n",
    "#     X[::40+np.random.randint(-20,20),:] = 80+np.random.randint(-60, 130)\n",
    "#     pil_X = Image.fromarray(X)\n",
    "#     pil_X.save(f'Data/computer_generated_lines/lined_{image}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
